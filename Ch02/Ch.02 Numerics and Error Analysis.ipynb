{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.4 EXERCISES"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1\n",
    "\n",
    "**When might it be preferable to use a fixed-point representation of real numbers over floating-point?  When might it be preferable to use a floating-point representation of real numbers over fixed-point?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A fixed-point representation is preferable when you have to take least significant digit into account precisely, like in economics domein.  On the other hand, a floating-point representation is preferable when you deal with very large (or small) scale number and the least significant digit is not so important, like scientific calculation such as astronomy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## 2.2\n",
    "\n",
    "**(\"Extraterrestrial chemistry\") Suppose we are programming a planetary rover to analyze the chemicals in a gas found on a neighboring planet.  Our rover is equipped with a flask of volume $0.5 m^3$ and also has pressure and temperature sensors.  Using the sensor readouts from a given sample, we would like our lover to determine the amount of gas our flask contains.**\n",
    "\n",
    "**One of the fundamental physical equations describing a gas is the Ideal Gas Law $PV = nRT$, which states:$$\n",
    "(P)\\text{ressure}\\cdot(V)\\text{olume} = \\text{amoun}(n)\\text{t of gas}\\cdot R \\cdot (T)\\text{emperature,}\n",
    "$$ where $R$ is the ideal gas constant, approximately equal to $8.31\\mathrm{J \\cdot mol^{-1}\\cdot K^{-1}}$.  Here, $P$ is in pascals, $V$ is in cubic meters, $n$ is in moles, and $T$ is in kelvin.  We will use this equation to approximate $n$ given the other variables.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(a) Describe any forms of rounding, discretization, modeling and input error that can occur when solving this problem.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Rounding error\n",
    "\n",
    "    This error could occur everytime when we try to multiply or divide the actual values of $P, V, R, T$.  Using the approximated gas constant $8.31\\mathrm{J \\cdot mol^{-1}\\cdot K^{-1}}$ also involves rounding error.\n",
    "    \n",
    "\n",
    "* Discretization error\n",
    "\n",
    "    Measured values by the sensors are originally continuous, but discretized in order to be processed by computers, as well as the intervals to sense.\n",
    "\n",
    "\n",
    "* Modeling error\n",
    "\n",
    "    The ideal gas law is actually an idealized model of the behavior of gas, which excludes the effect of the volume of gas moleculars and any interaction between them, thus this equation includes some error which amount depends on the kind of the gas.\n",
    "\n",
    "\n",
    "* Input error\n",
    "\n",
    "   Signals from sensors have more or less noises in its nature.  This property causes input error."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(b) Our rover's pressure and temp;erature sensors do not have perfect accuracy.  Suppose the pressure and temperature sensor measurements are accurate to within $\\pm\\epsilon _p$ and $\\pm\\epsilon _T$, respectively.  Assuming $V, R$ and fundamental arithmetic operations like $+$ and $\\times$ induce no errors, bound the relative forward error in computing $n$, when $0 < \\epsilon_p << P$ and $0 < \\epsilon_T << T$.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "According to the Ideal Gas Law,"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{equation}\n",
    "\\begin{split}\n",
    "  n &= \\frac{(P \\pm \\epsilon_P)V}{R(T \\pm \\epsilon_T)} \\\\\n",
    "    &= \\frac{PV}{RT}(1 \\pm \\frac{\\epsilon_P}{P})(1 \\pm \\frac{\\epsilon_T}{T})^{-1} \\\\\n",
    "    &\\approx \\frac{PV}{RT}(1 \\pm \\frac{\\epsilon_P}{P})(1 \\mp \\frac{\\epsilon_T}{T}) \\qquad \\text{since $0 < \\epsilon_p << P$ and $0 < \\epsilon_T << T$} \\\\\n",
    "\\end{split}\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hense, the relative forward error $e$ is:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{equation}\n",
    "\\begin{split}\n",
    " e &\\approx (1 \\pm \\frac{\\epsilon_P}{P})(1 \\mp \\frac{\\epsilon_T}{T}) - 1 \\\\\n",
    "   &\\le (1 + \\frac{\\epsilon_P}{P})(1 + \\frac{\\epsilon_T}{T}) - 1 \\\\\n",
    "\\end{split}\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(c) Continuing  the previous part, suppose $P = 100\\mathrm{Pa}, T = 300\\mathrm{K}, \\epsilon_P = 1\\mathrm{Pa}$, and $\\epsilon_T = 0.5\\mathrm{K}$.  Derive upper bounds for the worst absolute and relative erros that we could obtain from a computation of $n$.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The worst absolute error;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{equation}\n",
    "  \\frac{100\\mathrm{Pa}\\cdot0.5\\mathrm{m^3}}{8.31\\mathrm{J\\cdot mol^{-1}}\\cdot 300\\mathrm{K}}\\biggl\\{(1 + \\frac{1\\mathrm{Pa}}{100\\mathrm{Pa}})(1 + \\frac{0.5\\mathrm{K}}{300\\mathrm{K}}) - 1\\biggr\\} = 0.00023432\\cdots\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The worst relative error is:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{equation}\n",
    "\\begin{split}\n",
    "  (1 + \\frac{1\\mathrm{Pa}}{100\\mathrm{Pa}})(1 + \\frac{0.5\\mathrm{K}}{300\\mathrm{K}}) - 1 &= 0.011683\\cdots \\\\\n",
    "                                         &\\approx 1.17\\%\n",
    "\\end{split}\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(d) Experiment with the perturbing  the variables $P$ and $T$.  Based on how much your estimate of n changes between the experiments, suggest when this  problem is  well-conditioned or ill-conditioned.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "According to the Ideal Gas Law,"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{equation}\n",
    "  \\frac{P}{T} = n\\frac{R}{V}\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Using this relation, we can compute the condition number of $n$:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{equation}\n",
    "\\begin{split}\n",
    "  c &= \\frac{\\text{forward error}}{\\text{backward error}} \\\\\n",
    "    &= \\frac{|n - n_0|}{\\bigl|\\frac{P + \\epsilon_P}{T + \\epsilon_T} - \\frac{P}{T}\\bigr|} \\\\\n",
    "    &= \\frac{|n - n_0|}{\\bigl|\\frac{R}{V}(n - n_0)\\bigr|} \\\\\n",
    "    &= \\frac{V}{R}\n",
    "\\end{split}\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From this, we can see that this problem is well-conditioned if $V < R$ and ill-conditioned if $V > R$. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "##  2.3\n",
    "\n",
    "**In contrast to the \"absolute\" condition number introduced in this chapter, we can define the \"relative\" condition number of a problem to be $$\n",
    "  \\kappa_{\\text{rel}} \\equiv \\frac{\\text{relative forward error}}{\\text{relative backward error}}\n",
    "$$**\n",
    "\n",
    "**In some cases, the relative condition number of a problem can yield better insights into its sensitivity.**\n",
    "\n",
    "**Suppose we wish to evaluate a function $f:\\mathbb{R}\\rightarrow\\mathbb{R}$ at a point $x \\in \\mathbb{R}$, obtaining $y \\equiv f(x)$.  Assuming $f$ is smooth, compare the absolute and relative condition numbers of computing $y$ at $x$.  Additionaly, provide examples of functions $f$ with large and small relative condition numbers for this problem near $x = 1$.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "According to Taylor's theorem,\n",
    "\n",
    "\\begin{equation}\n",
    "\\begin{split}\n",
    "  y + \\Delta y &= f(x + \\Delta x) \\\\\n",
    "               &\\approx f(x) + \\Delta x f'(x) \\\\\n",
    "               &= y + \\Delta x f'(x)\n",
    "\\end{split}\n",
    "\\end{equation}\n",
    "\\begin{equation}\n",
    "  \\implies \\Delta y = \\Delta x f'(x)\n",
    "\\end{equation}\n",
    "\n",
    "Hense, the condition numbers are:\n",
    "\n",
    "\\begin{equation}\n",
    "\\begin{split}\n",
    "  \\text{absolute : } \\kappa &= \\frac{|\\Delta x |}{|\\Delta y |} \\\\\n",
    "                            &= \\frac{|\\Delta x |}{|\\Delta x f'(x)|} \\\\\n",
    "                            &= \\frac{1}{|f'(x)|} \\\\\n",
    "  \\text{relative : } \\kappa_{\\text{rel}} &= \\frac{|\\Delta x / x|}{|\\Delta y / y|} \\\\\n",
    "                        &= \\frac{|\\Delta x / x|}{|\\Delta x f'(x)/f(x)|} \\\\\n",
    "                        &=  \\frac{|f(x)|}{|x f'(x)|}\n",
    "\\end{split}\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The example function $f$ of large relative condition number near $x = 1$ is $f(x) = x^{0.001}$:\n",
    "\n",
    "\\begin{equation}\n",
    "\\begin{split}\n",
    "  \\kappa_{\\text{rel}} &= \\frac{|x^{0.001}|}{|x\\cdot0.001x^{-0.999}|} \\\\\n",
    "                      &= \\frac{|x^{0.001}|}{|0.001x^{0.001}|} \\\\\n",
    "                      &= 1000\n",
    "\\end{split}\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The example function $f$ of small relative condition number near $x = 1$ is $f(x) = x^{1000}$:\n",
    "\n",
    "\\begin{equation}\n",
    "\\begin{split}\n",
    "  \\kappa_{\\text{rel}} &= \\frac{|x^{1000}|}{|x\\cdot1000x^{999}|} \\\\\n",
    "                      &= \\frac{|x^{1000}|}{|1000x^{1000}|} \\\\\n",
    "                      &= 0.001\n",
    "\\end{split}\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## 2.4\n",
    "\n",
    "**Suppose $f:\\mathbb{R}\\rightarrow\\mathbb{R}$ is infinitely differentiable, and we wish to write algorithms for finding $x^{\\ast}$ minimizing $f(x)$.  Our algorithm outputs $x_{\\text{est}}$, an approximation of $x^{\\ast}$.  Assuming that in our context this problem is equivalent to finding roots of $f'(x)$, write expressions for:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "**(a) Forward error of the approximation**\n",
    "\n",
    "\\begin{equation}\n",
    "  |x_{\\text{est}} - x^{\\ast}|\n",
    "\\end{equation}\n",
    "\n",
    "**(b) Backward error of the approximation**\n",
    "\n",
    "\\begin{equation}\n",
    "  |f'(x_{\\text{est})} - f'(x^{\\ast})| = |f'(x_{\\text{est})}|\n",
    "\\end{equation}\n",
    "\n",
    "**(c) Conditioning number of this minimization problem near $x^{\\ast}$**\n",
    "\n",
    "Define $\\epsilon = x_{\\text{est}} - x^{\\ast}$, then the condition number $c$ is:\n",
    "\n",
    "\\begin{equation}\n",
    "\\begin{split}\n",
    "  c &= \\frac{|x_{\\text{est}} - x^{\\ast}|}{| f'(x_{\\text{est})} - f'(x^{\\ast}) |} \\\\\n",
    "    &= \\frac{|\\epsilon|}{|f'(x^{\\ast} + \\epsilon) - f'(x^{\\ast})|} \\\\\n",
    "    &= \\frac{1}{\\bigl|\\frac{f'(x^{\\ast} + \\epsilon) - f'(x^{\\ast})}{\\epsilon}\\bigr|}\n",
    "    &\\approx \\frac{1}{|f''(x^{\\ast})|}\n",
    "\\end{split}\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## 2.5\n",
    "\n",
    "**Suppose we are given a list of floating-point values $x_1, x_2, \\dots , x_n$.  The following quantity, known as their \"log-sum-exp,\" appears in many machine learning algorithms:**\n",
    "\n",
    "**$$\n",
    " l(x_1, \\dots, x_n) \\equiv \\ln \\biggl[\\displaystyle\\sum_{k=1}^{n}e^{x_k}\\biggr].\n",
    "$$**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(a) The value $p_k \\equiv e^{e^{x_k}}$ often represents a probability $p_k \\in (0, 1]$.  In this case, what is the range of possible $x_k$'s?**\n",
    "\n",
    "\\begin{equation}\n",
    "  -\\infty < x_k \\le 0\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(b) Suppose many of the $x_k$'s are very negative($x_k \\ll 0$).  Explain why evaluating the log-sum-exp formula s written above may cause numerical error in this case.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since $\\displaystyle\\lim_{y \\rightarrow 0^+}y = -\\infty$, $l(x_1, \\dots, x_n)$ goes to very negative as $x_1, x_2,\\dots,x_k \\ll 0 \\implies \\displaystyle\\sum_{k=1}^{n}e^{x_k}\\ll 1$. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(c) Show that for any $a \\in \\mathbb{R}$, $$\n",
    " l(x_1, x_2, \\dots, x_n) = a + \\ln\\biggl[\\displaystyle\\sum_{k=1}^{n} e^{x_k - a}\\biggr].\n",
    "$$**\n",
    "\n",
    "**To avoid the issues you explained in 2.5b, suggest a value of $a$ that may improve the stability of computing $l(x_1, x_2, \\dots, x_n)$.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{equation}\n",
    "\\begin{split}\n",
    "  a + \\ln\\biggl[\\displaystyle\\sum_{k=1}^{n} e^{x_k - a}\\biggr] &= a + \\ln\\biggl[\\displaystyle e^{-a}\\sum_{k=1}^{n} e^{x_k}\\biggr] \\\\\n",
    "                                                               &= a + \\ln e^{-a} + \\ln\\biggl[\\sum_{k=1}^{n} e^{x_k}\\biggr] \\\\\n",
    "                                                               &= a + (-a) + \\ln\\biggl[\\sum_{k=1}^{n} e^{x_k}\\biggr] \\\\\n",
    "                                                               &= \\ln\\biggl[\\sum_{k=1}^{n} e^{x_k}\\biggr] \\\\\n",
    "                                                               &= l(x_1, x_2, \\dots, x_n)\n",
    "\\end{split}\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The value of $a$ that may improve the stability of $l$ is $a = \\min\\{x_1, x_2, \\dots, x_n\\}$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## 2.6\n",
    "\n",
    "**(\"z-fighting\") A typical pipeline in computer graphics draws three-dimensional surfaces on the screen, one at a time.  To avoid rendering a far-away surface on top of a close one, most implementations use a _z-buffer_, which maintains a double-precision depth value $z(x, y) \\ge 0$ representing the depth of the closest object to the camera at each screen coordinate $(x, y)$.  A new object is rendered at $(x, y)$ only when its $z$ value is smaller than the one currently in the _z-buffer_.**\n",
    "\n",
    "**A common artifact when rendering using _z_-buffering known as _z-fighting_ is shown in Figure 2.4.  Here, two surfaces overlap at some visible points.  Why are there rendering artifacts in this region?  Propose a strategy for avoiding this argtifact; there are many possible resolutions.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This artifact occures when the distance along z-axis between two objects is less than the smallest precision of the depth buffer, in which case the renderer cannot decide which surface of the objects is front of the other.\n",
    "There are several ways to prevent this issue as noted in the question.  One way to avoid this artifact is simply to use the depth buffer with more precision.  Another way is to set the near-clipping plane and far-clipping plane close to the artifact area in 3 dimensional space, but this approach won't apply to the whole range of the 3d space.  If the z-depth value is stored in the buffer as the reciprocal of the world space depth, make the value reversed ($z \\rightarrow 1 - z$) is a good way to make the precision distributed linealy.(https://developer.nvidia.com/content/depth-precision-visualized)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## 2.7\n",
    "\n",
    "**(Adapted from Stanford CS 205A, 2012) Thanks to floating-point arithmetic, in most implementations of numerical algorithms we cannot expect that computations involving fractional values can be can be carried out with 1000% precision.  Instead, wvery time we do a numerical operation we induce the potential for error.  Many models exist for studying how this error affects the quality of a numerical oepration; in this problem, we will explore one common model.**\n",
    "\n",
    "**Suppose we care about an operation $\\diamond$ between two scalars $x$ and $y$; here $\\diamond$ might stand for $+, -, \\times, \\div$, and so on.  As a model for the error that occurs when computing $x \\diamond y$, we will say that evaluating $x \\diamond y$ on the computer yields a number $(1 + \\epsilon)(x \\diamond y)$ for some number $\\epsilon$ satisfying $0 \\le |\\epsilon| < \\epsilon_{\\text{max}} \\ll 1$; we will assume $\\epsilon$ can depend on $\\diamond$, $x$, and $y$.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(a) Why is this a reasonable model for modeling numerical issues in floating-point arithmetic?  For example, why does this make more sense than assuming that the output of evaluating $x \\diamond y$ is $(x \\diamond y) + \\epsilon$?**\n",
    "\n",
    "Because we will assume that the error on evaluating operation $x \\diamond y$ depends on $\\diamond$, $x$, $y$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(b) (Revised by B. Jo) Suppose we are given two vectors $\\vec{x}, \\vec{y} \\in \\mathbb{R}^n$ and compute their dot product as $s_n$ via the recurrence:**\n",
    "\n",
    "\\begin{align*}\n",
    "  s_0 &\\equiv 0 \\\\\n",
    "  s_k &\\equiv s_{k-1} + x_k y_k.\n",
    "\\end{align*}\n",
    "\n",
    "**In practice, both the addition and multiplication steps of computing $s_k$ from $s_{k-1}$ induce numerical error.  Use $\\hat{s}_k$ to denote the actual value computed incorporationg numerical error, and denote $e_k \\equiv |\\hat{s}_k - s_k|$.  Show that**\n",
    "\n",
    "\\begin{equation}\n",
    "\\label{eq:2.7}\n",
    "|e_n| \\le n\\epsilon_{\\text{max}}\\bar{s}_n + O(n\\epsilon_{\\text{max}}^2\\bar{s}_n),\n",
    "\\end{equation}\n",
    "\n",
    "**where $\\bar{s}_n \\equiv \\sum_{k=1}^{n}|x_k||y_k|$**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I will show the inequality(\\ref{eq:2.7}) using induction.\n",
    "\n",
    "When $n = 1$,\n",
    "\n",
    "\\begin{equation}\n",
    "  \\hat{s_1} = (1 + \\epsilon^{\\times})x_1y_1\n",
    "\\end{equation}\n",
    "\n",
    "\\begin{equation}\n",
    "\\begin{split}\n",
    "  |e_1| &= |\\hat{s_1} - s_1| \\\\\n",
    "        &= |\\epsilon^{\\times}x_1y_1| \\\\\n",
    "        &\\le \\epsilon_{\\text{max}}\\bar{s_1}\n",
    "\\end{split}\n",
    "\\end{equation}\n",
    "\n",
    "We assume the inequality holds when $n = k (\\ge 1)$:\n",
    "\n",
    "\\begin{equation}\n",
    "  |e_k| = |\\hat{s_k} - s_k| \\le k\\epsilon_{\\text{max}}\\bar{s}_k + O(k\\epsilon_{\\text{max}}^2\\bar{s}_k),\n",
    "\\end{equation}\n",
    "\n",
    "Then, when $n = k + 1$:\n",
    "\n",
    "\\begin{equation}\n",
    "  \\hat{s}_{k+1} = (1 + \\epsilon^+)\\bigl(\\hat{s}_k + (1 + \\epsilon^{\\times})x_{k+1}y_{k+1}\\bigr)\n",
    "\\end{equation}\n",
    "\n",
    "\\begin{equation}\n",
    "\\begin{split}\n",
    "  |e_{k+1}| &= |\\hat{s}_{k+1} - s_{k+1}| \\\\\n",
    "            &= \\bigl|(1 + \\epsilon^+)\\bigl(\\hat{s}_k + (1 + \\epsilon^{\\times})x_{k+1}y_{k+1}\\bigr) - (s_k + x_{k+1}y_{k+1})\\bigr| \\\\\n",
    "            &= \\bigl|(\\hat{s}_k - s_k) + \\epsilon^+\\hat{s_k} + (\\epsilon^+ + \\epsilon^{\\times} + \\epsilon^+\\epsilon^{\\times})x_{k+1}y_{k+1}\\bigr| \\\\\n",
    "            &= \\bigl|e_k + \\epsilon^+(s_k + e_k) + (\\epsilon^+ + \\epsilon^{\\times} + \\epsilon^+\\epsilon^{\\times})x_{k+1}y_{k+1}\\bigr| \\\\\n",
    "            &\\le |e_k| + \\epsilon^+|s_k| + \\epsilon|^+e_k| + (\\epsilon^+ + \\epsilon^{\\times} + \\epsilon^+\\epsilon^{\\times})|x_{k+1}||y_{k+1}| \\\\\n",
    "            &\\le |e_k| + \\epsilon_{\\text{max}}|s_k| + \\epsilon_{\\text{max}}|e_k| + (2\\epsilon_{\\text{max}} + \\epsilon_{\\text{max}}^2)|x_{k+1}||y_{k+1}| \\\\\n",
    "            &\\le k\\epsilon_{max}\\bar{s}_k + O(k\\epsilon_{\\text{max}}^2\\bar{s}_k) + \\epsilon_{\\text{max}}\\bar{s}_k + \\epsilon_{\\text{max}}\\bigl(k\\epsilon_{max}\\bar{s}_k + O(k\\epsilon^2\\bar{s}_k)\\bigr) + \\bigl((k+1)\\epsilon_{\\text{max}} + k\\epsilon_{\\text{max}}^2\\bigr)|x_{k+1}||y_{k+1}| \\\\\n",
    "            &= (k + 1)\\epsilon_{\\text{max}}\\bar{s}_{k+1} + k\\epsilon_{\\text{max}}^2\\bar{s}_{k+1} + O(k\\epsilon_{\\text{max}}^2\\bar{s}_k) + O(k\\epsilon_{\\text{max}}^3\\bar{s}_k) \\\\\n",
    "            &\\le (k + 1)\\epsilon_{\\text{max}}\\bar{s}_{k+1} + O(k\\epsilon_{\\text{max}}^2\\bar{s}_k) \\\\\n",
    "            &\\le (k + 1)\\epsilon_{\\text{max}}\\bar{s}_{k+1} + O\\bigl((k+1)\\epsilon_{\\text{max}}^2\\bar{s}_k\\bigr)\n",
    "\\end{split}\n",
    "\\end{equation}\n",
    "\n",
    "Hense, the inequality holds when $n = k +1$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## 2.8\n",
    "\n",
    "**Argue using the error model from the previous problem that the relative error of computing $x - y$ for $x, y > 0$ can be unbounded; assume that htere is error in representing $x$ and $y$ in addition to error computing the difference.  This phenomenon is known as \"catastrophic cancellation\" and can cause serious numerical issues.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let the error computing difference as $\\epsilon^-$ and those in representing $x$ and $y$ as $\\epsilon^x$, $\\epsilon^y$, respectively.  Assuming $y$ is very close to $x$ and written as $y = x + \\delta$, then the relative error $e$ is:\n",
    "\n",
    "\\begin{equation}\n",
    "\\begin{split}\n",
    "  e &= \\frac{(1 + \\epsilon^-)\\{(x + \\epsilon^x) - (y + \\epsilon^y)\\}}{x - y} - 1 \\\\\n",
    "    &= \\frac{(1 + \\epsilon^-)\\{(x + \\epsilon^x) - (x + \\delta + \\epsilon^y)\\}}{x - (x + \\delta)} - 1 \\\\\n",
    "    &= \\epsilon^- + \\frac{\\epsilon^y - \\epsilon^x}{\\delta}\n",
    "\\end{split}\n",
    "\\end{equation}\n",
    "\n",
    "According to this equation, $|e|$ goes to infinity when $\\delta \\rightarrow 0$.  Hense, the relative error can be unbound when $x$ and $y$ are very close to each other."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## 2.9\n",
    "\n",
    "**In this problem, we continue to explore the conditioning of root-finding.  Suppose $f(x)$ and $p(x)$ are smooth functions of $x \\in \\mathbb{R}$.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "**(a) Thanks to inaccuracies in how we evaluate or express $f(x)$, we might accidentally compute roots of a perturbation $f(x) + \\epsilon p(x)$.  Take $x^{\\ast}$ to be a root of $f$, so $f(x^{\\ast}) = 0$.  If $f'(x^{\\ast}) \\ne 0$, for small $\\epsilon$ we can write a function $x(\\epsilon)$ such that $f(x(\\epsilon)) + \\epsilon p(x(\\epsilon)) = 0$, with $x(0) = x^{\\ast}$.  Assuming such a function exists and is differentiable, show:$$\n",
    "    \\frac{dx}{d\\epsilon}\\bigg|_{\\epsilon = 0} = -\\frac{p(x^{\\ast})}{f'(x^{\\ast})}.\n",
    "$$**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since $f(x(\\epsilon)) + \\epsilon p(x(\\epsilon)) = 0$,\n",
    "\n",
    "\\begin{align}\n",
    "  \\frac{d}{d\\epsilon}\\bigl\\{f(x(\\epsilon)) + \\epsilon p(x(\\epsilon))\\bigr\\} &=\n",
    "    f'(x)\\cdot\\frac{dx}{d\\epsilon} + p(x) + \\epsilon p'(x) = 0 \\\\\n",
    "  \\implies \\frac{dx}{d\\epsilon} &= -\\frac{p(x)}{f'(x) + \\epsilon p'(x)}\n",
    "\\end{align}\n",
    "\n",
    "When $\\epsilon = 0$,\n",
    "\n",
    "\\begin{equation}\n",
    "\\begin{split}\n",
    "  \\frac{dx}{d\\epsilon}\\bigg|_{\\epsilon=0} &= -\\frac{p(x(0))}{f'(x(0)) + 0 \\cdot p'(x(0))} \\\\\n",
    "                                          &= -\\frac{p(x^{\\ast})}{f'(x^{\\ast})} \\qquad \\text{since  $x(0) = x^{\\ast}$} \\\\\n",
    "\\end{split}\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(b) Assume $f(x)$ is given by Wilkinson's polynomial[131]: $$\n",
    "  f(x) \\equiv (x - 1)\\cdot(x - 2)\\cdot(x - 3)\\cdot\\cdots\\cdot(x - 20).\n",
    "$$  We could have expanded $f(x)$ in the monomial basis as $f(x) = a_0 + a_1x + a_2x^2 + \\cdots + a_{20}x^{20}$, for appropriate choices of $a_0, \\dots, a_{20}$.  If we express the coefficient $a_{19}$ inaccurately, we could use the model from Exercise 2.9a with $p(x) \\equiv x^{19}$ to predict how much root-finding will suffer.  For these choices of $f(x)$ and $p(x)$, show: $$\n",
    "    \\frac{dx}{d\\epsilon}\\bigg|_{\\epsilon = 0, x^{\\ast} = j} = -\\displaystyle\\prod_{k \\ne j}\\frac{j}{j - k}.\n",
    "$$**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Since $f'(x) = \\sum_{i=1}^{20}\\prod_{k = 1, k \\ne i}^{20}(x - k)$, \n",
    "\n",
    "\\begin{equation}\n",
    " f'(j) = \\displaystyle\\prod_{k = 1, k \\ne j}^{20}(j - k)\n",
    "\\end{equation}\n",
    "\n",
    "\\begin{equation}\n",
    "\\begin{split}\n",
    "  \\frac{dx}{d\\epsilon}\\bigg|_{\\epsilon=0, x^{\\ast}=j} &= -\\frac{p(j)}{f'(j)} \\\\\n",
    "                                          &= -\\frac{j^{19}}{\\prod_{k = 1, k \\ne j}^{20}(j - k)} \\\\\n",
    "                                          &= -\\prod_{k = 1, k \\ne j}^{20}\\frac{j}{j - k}\n",
    "\\end{split}\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(c) Compare $\\frac{dx}{d\\epsilon}$ from the previous part for $x^{\\ast} = 1$ and $x^{\\ast} = 20$.  Which root is more stable to this perturbation?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I'll compare about $x = 1, 2, \\dots ,20$. The relation between $x^{\\ast}$ and $\\bigl|\\frac{dx}{d\\epsilon}\\bigr|$ is:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-09T10:05:14.829573Z",
     "start_time": "2017-11-09T10:05:14.812561Z"
    },
    "hide_input": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>|dx/dε|</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>x*</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8.220635e-18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8.188963e-11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.633824e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.189621e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6.077420e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>5.824842e+01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2.542436e+03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>5.969559e+04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>8.393275e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>7.594058e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>4.644457e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1.985032e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>6.055586e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>1.332968e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>2.119065e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>2.407514e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>1.904402e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>9.955867e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>3.090135e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>4.309980e+07</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         |dx/dε|\n",
       "x*              \n",
       "1   8.220635e-18\n",
       "2   8.188963e-11\n",
       "3   1.633824e-06\n",
       "4   2.189621e-03\n",
       "5   6.077420e-01\n",
       "6   5.824842e+01\n",
       "7   2.542436e+03\n",
       "8   5.969559e+04\n",
       "9   8.393275e+05\n",
       "10  7.594058e+06\n",
       "11  4.644457e+07\n",
       "12  1.985032e+08\n",
       "13  6.055586e+08\n",
       "14  1.332968e+09\n",
       "15  2.119065e+09\n",
       "16  2.407514e+09\n",
       "17  1.904402e+09\n",
       "18  9.955867e+08\n",
       "19  3.090135e+08\n",
       "20  4.309980e+07"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "k = np.arange(1, 21)\n",
    "j = k[:, np.newaxis]\n",
    "j_k = j - k\n",
    "j_k[j_k[:] == 0] = j.flat\n",
    "dxde = (j / j_k).prod(axis=1)\n",
    "df = pd.DataFrame({\"|dx/dε|\":np.absolute(dxde)}, index=k)\n",
    "df.index.name = \"x*\"\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "According to this result, the most stable root is $x^{\\ast} = 1$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.10\n",
    "\n",
    "**The roots of the quadratic function $ax^2 + bx + c$ are given by the _quadratic equation_ $$\n",
    "  x^{\\ast} \\in \\frac{-b \\pm \\sqrt{b^2 - 4ac}}{2a}\n",
    "$$**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(a) Prove the alternative formula $$\n",
    "    x^{\\ast} \\in \\frac{-2c}{b \\pm \\sqrt{b^2 - 4ac}}\n",
    "$$**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{equation}\n",
    "\\begin{split}\n",
    "    \\frac{-b \\pm \\sqrt{b^2 - 4ac}}{2a} &= \\frac{(-b \\pm \\sqrt{b^2 - 4ac})(b \\pm \\sqrt{b^2 - 4ac)}}{2a(b \\pm \\sqrt{b^2 - 4ac})} \\\\\n",
    "                                       &= \\frac{-b^2 + (b^2 - 4ac)}{2a(b \\pm \\sqrt{b^2 - 4ac})} \\\\\n",
    "                                       &= \\frac{-4ac}{2a(b \\pm \\sqrt{b^2 - 4ac})} \\\\\n",
    "                                       &= \\frac{-2c}{b \\pm \\sqrt{b^2 - 4ac}} \\\\\n",
    "\\end{split}\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(b) Propose a numerically stable algorithm for solving the quadratic equation.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Error of computing $x - y$ can be unbounded from the discuttion of the problem 2.8, which indicates that $b \\pm \\sqrt{b^2 - 4ac}$ or $-b \\pm \\sqrt{b^2 - 4ac}$ may cause disatrous error when the two terms have the same sign. This reason gives us the stable algorithm for the solution of quadratic problem:\n",
    "\n",
    "\\begin{equation}\n",
    "\\begin{split}\n",
    "  x^{\\ast} \\in \\left\\{\\frac{-b - \\sqrt{b^2 - 4ac}}{2a}, \\frac{-2c}{b + \\sqrt{b^2 - 4ac}}\\right\\} \\quad \\text{when } b \\ge 0, \\\\\n",
    "  x^{\\ast} \\in \\left\\{\\frac{-b + \\sqrt{b^2 - 4ac}}{2a}, \\frac{-2c}{b - \\sqrt{b^2 - 4ac}}\\right\\} \\quad \\text{when } b < 0. \\\\\n",
    "\\end{split}\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## 2.11\n",
    "\n",
    "**One technique for tracking uncertainty in a calculation is the use of _interval arithmetic_.  In this system, an uncertain value for a variable $x$ is represented as the interval $[x] \\equiv [\\underline{x}, \\bar{x}]$ representing the range of possible values for $x$, from $\\underline{x}$ to $\\bar{x}$.  Assuming infinite-precision arithmetic, give update rules for the following in terms of $\\underline{x}$, $\\bar{x}$, $\\underline{y}$, and $\\bar{y}$:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* **$[x] + [y]$**\n",
    "\n",
    "Since $\\underline{x} + \\underline{y} \\le [x] + [y] \\le \\bar{x} + \\bar{y}$, \n",
    "\n",
    "\\begin{equation}\n",
    "  [x] + [y] = [\\underline{x} + \\underline{y},\\; \\bar{x} + \\bar{y}]\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* **$[x] - [y]$**\n",
    "\n",
    "Since $\\underline{x} - \\bar{y} \\le [x] - [y] \\le \\bar{x} - \\underline{y}$, \n",
    "\n",
    "\\begin{equation}\n",
    "  [x] - [y] = [\\underline{x} - \\bar{y},\\; \\bar{x} - \\underline{y}]\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* **$[x] \\times [y]$**\n",
    "\n",
    "Since $\\underline{x} \\times \\underline{y} \\le [x] \\times [y] \\le \\bar{x} \\times \\bar{y}$, \n",
    "\n",
    "\\begin{equation}\n",
    "  [x] \\times [y] = [\\underline{x} \\times \\underline{y},\\; \\bar{x} \\times \\bar{y}]\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* **$[x] \\div [y]$**\n",
    "\n",
    "Since $\\underline{x} \\div \\bar{y} \\le [x] \\div [y] \\le \\bar{x} \\div \\underline{y}$, \n",
    "\n",
    "\\begin{equation}\n",
    "  [x] \\div [y] = [\\underline{x} \\div \\bar{y},\\; \\bar{x} \\div \\underline{y}]\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* **$[x]^{1/2}$**\n",
    "\n",
    "Since $\\underline{x}^{1/2} \\le [x]^{1/2} \\le \\bar{x}^{1/2}$,\n",
    "\n",
    "\\begin{equation}\n",
    "  [x]^{1/2} = [\\underline{x}^{1/2},\\; \\bar{x}^{1/2}]\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Additionally, propose a conservative modification for finite-precision arithmetic.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Letting $\\epsilon^{\\diamond}$ as the error of computing operation $\\diamond$, and $\\epsilon_x$, $\\epsilon_y$ as errors of values $x$, $y$ respectively, we can write the error of finite-precision arithmetic as:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* **$[x] + [y]$**\n",
    "\n",
    "\\begin{equation}\n",
    "  [x] + [y] = (1 + \\epsilon^+)\\left((x + \\epsilon_x) + (y + \\epsilon_y)\\right)\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* **$[x] - [y]$**\n",
    "\n",
    "\\begin{equation}\n",
    "  [x] - [y] = (1 + \\epsilon^-)\\left((x + \\epsilon_x) - (y + \\epsilon_y)\\right)\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* **$[x] \\times [y]$**\n",
    "\n",
    "\\begin{equation}\n",
    "  [x] \\times [y] = (1 + \\epsilon^{\\times})\\left((x + \\epsilon_x) \\times (y + \\epsilon_y)\\right)\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* **$[x] \\div [y]$**\n",
    "\n",
    "\\begin{equation}\n",
    "  [x] \\div [y] = (1 + \\epsilon^{\\div})\\left((x + \\epsilon_x) \\div (y + \\epsilon_y)\\right)\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* **$[x]^{1/2}$**\n",
    "\n",
    "Since $(x + h)^{1/2} \\approx x + h / 2$ when $h$ is small,\n",
    "\n",
    "\\begin{equation}\n",
    "  [x]^{1/2} \\approx x + (1 + \\epsilon^{\\div})\\frac{\\epsilon_x}{2}\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.12 \n",
    "\n",
    "**Algorithms for dealing with geometric primitives such as line segments and triangles are notoriously difficult to implement in a numerically stable fashion.  Here, we highlight a few ideas from \"ε-geometry,\" a technique built to deal with these issues [55].**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(a) Take $\\vec{p}, \\vec{q}, \\vec{r} \\in \\mathbb{R}^2$.  Why might it be difficult to determine whether $\\vec{p}$, $\\vec{q}$ and $\\vec{r}$ are collinear using finite-precision arithmetic?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One easy way to determin whether $\\vec{r}$ is on the line through $\\vec{p}$ and $\\vec{q}$ is to check if $(\\vec{r} - \\vec{q})\\times(\\vec{p} - \\vec{q}) = 0$.  However, the left expression doesn't always evaluate to $0$ even if these vectors are collinear due to finite-precision arithmetic.  It is difficult to set a value $\\epsilon$ under which the expression value is considered as $0$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "hide_input": false
   },
   "source": [
    "**(b) We will say $\\vec{p}$, $\\vec{q}$, and $\\vec{r}$ are ε-collinear if there exist $\\vec{p'}$ with $\\|\\vec{p}-\\vec{p'}\\|_2 \\le \\epsilon$, $\\vec{q'}$ with $\\|\\vec{q}-\\vec{q'}\\|_2 \\le \\epsilon$, and $\\vec{r'}$ with $\\|\\vec{r}-\\vec{r'}\\|_2 \\le \\epsilon$ such that $\\vec{p'}$, $\\vec{q'}$, and $\\vec{r'}$ are exactly collinear.  For fixed $\\vec{p}$ and $\\vec{q}$, sketch the region $\\{ \\vec{r} \\in \\mathbb{R}^2 : \\vec{p}, \\vec{q}, \\vec{r} \\: \\text{are $\\epsilon$-collinear}\\}$.  This region is known as the _ε-butterfly_ of $\\vec{p}$ and $\\vec{q}$.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The region is the blue area of the picture below.\n",
    "\n",
    "![Ex2-12(b) answer](Ex2-12b.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(c) An ordered triplet $(\\vec{p}, \\vec{q}, \\vec{r}) \\in \\mathbb{R}^2\\times\\mathbb{R}^2\\times\\mathbb{R}^2$ is ε-clockwise if the three points can be perturbed by at most distance $\\epsilon$ so that they form a triangle whose vertices are in clockwise order; we will consider collinear triplets to be both clockwise and coounterclockwise.  For fixed $\\vec{p}$ and $\\vec{q}$, sketch the region $\\{\\vec{r} \\in \\mathbb{R}^2 : (\\vec{p}, \\vec{q}, \\vec{r}) \\: \\text{is $\\epsilon$-clockwise}\\}$.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The region where $\\vec{r}$ is ε-clockwise only is the blue area of the picture below.\n",
    "\n",
    "![Ex2-12(c) answer](Ex2-12c.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(d) Show a triplet is ε-collinear if and only if it is both ε-clockwise and ε-counterclockwise.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The region $\\{\\vec{r} \\in \\mathbb{R}^2 : (\\vec{p}, \\vec{q}, \\vec{r}) \\: \\text{is $\\epsilon$-counterclockwise}\\}$ is depicted below.\n",
    "\n",
    "![Ex2-12(d)](Ex2-12d1.png)\n",
    "\n",
    "The intersection of the regions ε-clockwise and ε-counterclockwise is:\n",
    "\n",
    "![Ex2-12(d)](Ex2-12d2.png)\n",
    "\n",
    "This is the same as the region of **(b)**, which means a triplet is ε-collinear if and only if it is both ε-clockwise and ε-counterclockwise."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "**(e) A point $\\vec{x} \\in \\mathbb{R}^2$ is ε-inside the triangle $(\\vec{p}, \\vec{q}, \\vec{r})$ if and only if $\\vec{p}$, $\\vec{q}$, $\\vec{r}$ and $\\vec{x}$ can be moved by at most distance $\\epsilon$ such that the perturbed $\\vec{x'}$ is exactly inside the perturbed triangle $(\\vec{p'}, \\vec{q'}, \\vec{r'})$.  Show that when $\\vec{p}$, $\\vec{q}$, and $\\vec{r}$ are in (exactly) clockwise order, $\\vec{x}$ is inside $(\\vec{p}, \\vec{q}, \\vec{r})$ if and only if $(\\vec{p}, \\vec{q}, \\vec{x})$, $(\\vec{q}, \\vec{r}, \\vec{x})$, and $(\\vec{r}, \\vec{p}, \\vec{x})$ are all clockwise.  Is the same statement true if we relax to ε-inside and ε-clockwise?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "The region $\\{\\vec{x} \\in \\mathbb{R}^2 : (\\vec{p}, \\vec{q}, \\vec{x}) \\: \\text{is clockwise}\\}$ is:\n",
    "\n",
    "![(p,q,x) clockwise](Ex2-12e1.png)\n",
    "\n",
    "The region $\\{\\vec{x} \\in \\mathbb{R}^2 : (\\vec{q}, \\vec{r}, \\vec{x}) \\: \\text{is clockwise}\\}$ is:\n",
    "\n",
    "![(q,r,x) clockwise](Ex2-12e2.png)\n",
    "\n",
    "And the region $\\{\\vec{x} \\in \\mathbb{R}^2 : (\\vec{r}, \\vec{p}, \\vec{x}) \\: \\text{is clockwise}\\}$ is:\n",
    "\n",
    "![(r,p,x) clockwise](Ex2-12e3.png)\n",
    "\n",
    "Finally the intersection of all of the regions above is:\n",
    "\n",
    "![intersection](Ex2-12e4.png)\n",
    "\n",
    "Hense, $\\vec{x}$ is exactly inside a triangle $(\\vec{p}, \\vec{q}, \\vec{r})$ if and only if $(\\vec{p}, \\vec{q}, \\vec{x})$, $(\\vec{q}, \\vec{r}, \\vec{x})$, and $(\\vec{r}, \\vec{p}, \\vec{x})$ are all clockwise."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is not the case with ε-inside and ε-clockwise, though.  First of all, the ε-inside region of triangle $(\\vec{p}, \\vec{q}, \\vec{r})$ is depicted as below:\n",
    "\n",
    "![ε-inside](Ex2-12e5.png)\n",
    "\n",
    "As in problem **(c)**, the region $\\{\\vec{x} \\in \\mathbb{R}^2 : (\\vec{p}, \\vec{q}, \\vec{x}) \\: \\text{is $\\epsilon$-clockwise}\\}$ is:\n",
    "\n",
    "![(p,q,x) ε-clockwise](Ex2-12e6.png)\n",
    "\n",
    "Other ε-clockwise regions are:\n",
    "\n",
    "![(q,r,x) ε-clockwise](Ex2-12e7.png)\n",
    "![(r,p,x) ε-clockwise](Ex2-12e8.png)\n",
    "\n",
    "These intersection is:\n",
    "\n",
    "![intersection ε-clockwise](Ex2-12e9.png)\n",
    "\n",
    "This region is completely different from that of ε-inside.  Hense, we cannot determin ε-inside using ε-clockwise conditions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "_draft": {
   "nbviewer_url": "https://gist.github.com/10664fc8fd05b0ecc85a46bf7f257ac2"
  },
  "gist": {
   "data": {
    "description": "NumericalAlgorithms/Ch.02 Numerics and Error Analysis.ipynb",
    "public": true
   },
   "id": "10664fc8fd05b0ecc85a46bf7f257ac2"
  },
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  },
  "toc": {
   "colors": {
    "hover_highlight": "#DAA520",
    "navigate_num": "#000000",
    "navigate_text": "#333333",
    "running_highlight": "#FF0000",
    "selected_highlight": "#FFD700",
    "sidebar_border": "#EEEEEE",
    "wrapper_background": "#FFFFFF"
   },
   "moveMenuLeft": true,
   "nav_menu": {
    "height": "48px",
    "width": "252px"
   },
   "navigate_menu": true,
   "number_sections": false,
   "sideBar": true,
   "threshold": 4,
   "toc_cell": false,
   "toc_section_display": "block",
   "toc_window_display": false,
   "widenNotebook": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
